# DistilGPT-2 Chatbot 🗣️🤖

This repository contains a simple chatbot built using Hugging Face's `distilgpt2`, a distilled version of OpenAI’s GPT-2 model. The project demonstrates how to fine-tune and deploy a lightweight conversational model for custom text generation tasks.

---

## 📂 Project Structure

- `chatbot.py` – Core script to generate responses using the `distilgpt2` model.
- `requirements.txt` – Python dependencies required to run the chatbot.
- `notebooks/` – Jupyter notebooks for experimentation, testing, and analysis.

---

## 💡 Features

- Lightweight and efficient using `distilgpt2`
- Simple CLI interface for interactive conversations
- Easy to modify or extend for custom use-cases

---

## 📚 Built With

- [Hugging Face Transformers](https://huggingface.co/transformers/)
- Python
- PyTorch
- Streamlit

---

## 📌 Notes

- The model is fine-tuned but may generate generic or incoherent responses.
- Ideal as a baseline or prototype for more advanced chatbot pipelines (e.g., RAG, instruction tuning, etc.).

---

## 👩🏻‍💻 Author

Aditi Balaji – [LinkedIn](https://www.linkedin.com/in/aditibalaji) | [GitHub](https://github.com/Aditi-balaji-13)


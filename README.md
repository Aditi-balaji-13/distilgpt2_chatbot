# DistilGPT-2 Chatbot 🗣️🤖

This repository contains a simple chatbot built using Hugging Face's `distilgpt2`, a distilled version of OpenAI’s GPT-2 model. The project demonstrates how to fine-tune and deploy a lightweight conversational model for custom text generation tasks.

---

## 📂 Project Structure

- `chatbot.py` – Core script to generate responses using the `distilgpt2` model.
- `requirements.txt` – Python dependencies required to run the chatbot.
- `notebooks/` – Jupyter notebooks for experimentation, testing, and analysis.

---

## 🚀 How to Run

1. **Clone the Repository**  
'''
git clone https://github.com/Aditi-balaji-13/distilgpt2_chatbot.git
cd distilgpt2_chatbot
'''

2. **Install Requirements**
'''
pip install -r requirements.txt

'''
3. **Run the Chatbot**
'''
python chatbot.py
'''


4. **Interact**  
Enter any message, and get a generated response from the model!

---

## 💡 Features

- Lightweight and efficient using `distilgpt2`
- Simple CLI interface for interactive conversations
- Easy to modify or extend for custom use-cases

---

## 📚 Built With

- [Hugging Face Transformers](https://huggingface.co/transformers/)
- Python
- PyTorch

---

## 📌 Notes

- The model is not fine-tuned and may generate generic or incoherent responses.
- Ideal as a baseline or prototype for more advanced chatbot pipelines (e.g., RAG, instruction tuning, etc.).

---

## ✨ Future Improvements

- Add a front-end interface (e.g., Streamlit)
- Fine-tune on domain-specific data
- Integrate with speech-to-text and text-to-speech APIs

---

## 👩🏻‍💻 Author

Aditi Balaji – [LinkedIn](https://www.linkedin.com/in/aditibalaji) | [GitHub](https://github.com/Aditi-balaji-13)

